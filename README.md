# PPO for MxNet
*This code also origionally worked on with Chien-chein Huang and Sean Welleck as
part of a larger project*

The goal of this repository is to create running [PPO](https://openai.com/blog/openai-baselines-ppo/)
code (completely based off
of OpenAI's [baselines](https://github.com/openai/baselines)) using MxNet, as
no suitable implementation seems to be around.

I have added a main function to train a simple cart-pole example.
